"""get scores of the accumulator model"""
import argparse
import os
import sys
import pandas as pd
from lm_benchmark.count_util import count_ngrams

def parseArgs(argv):
    # Run parameters
    parser = argparse.ArgumentParser(description='Select test sets by freq')

    parser.add_argument('--root_path', type=str, default='/Users/jliu/PycharmProjects/freq_bias_benchmark/data/',
                        help='root path to the utterance and freq dir')

    parser.add_argument('--model', type=str, default='400',
                        help='model name')

    parser.add_argument('--test_set', type=str, default='gen',
                        help='which type of words to select; recep or exp')

    parser.add_argument('--ngram', type=int, default=1,
                        help='ngram to extract')

    return parser.parse_args(argv)



def accu_model_tok_stats(token_count,ref_corpus_size,gen_corpus_size=None):
    """Token Frequency stats for a token observed token_count times in the reference corpus (of size ref_corpus_size)
    in new corpus generated by an accumulator model with perfect memory trained on the reference corpus.
    The generated corpus size (gen_corpus_size) by default is of the same size as the reference, but can differ.
    Returned values:
       p_miss: probability of missing the word in the generated corpus
       p_once: probability of observing the word once
       p_same: probability of observing the word with the expected count (taking into account differences in corpus size)
       p_less: probability of observing the word with less than the expected count (including zero)
       p_more: probability of observing the word with more than the expected count
       score: expected score where score=1 if observed count is seen more than expected and -1 if less
    """
    if gen_corpus_size is None:
        gen_corpus_size=ref_corpus_size

    prob_token=token_count/ref_corpus_size
    gen_token_count=int(round(1.0*token_count/ref_corpus_size*gen_corpus_size))

    pmiss=p_miss(prob_token,gen_corpus_size)
    ponce=p_obs_k(1,prob_token,gen_corpus_size)
    psame=p_obs_k(gen_token_count,prob_token,gen_corpus_size)
    pless=p_obs_less_than_k(gen_token_count,prob_token,gen_corpus_size)
    pmore=1-psame-pless
    score=pless*-1+pmore
    return {'p_miss':pmiss,'p_once':ponce,'p_same':psame,'p_less':pless,'p_more':pmore,'score':sco




def main(argv):
    # load args
    args = parseArgs(argv)
    test_set = args.test_set
    ngram = args.ngram
    ref_path = args.root_path + 'utt/' + args.model + '/gen.csv'
    test_path = args.root_path + 'utt/' + args.model + '/'+ test_set + '.csv'
    out_path = args.root_path + 'freq/' + args.model + '/' + str(ngram) + '_gram/'
    if not os.path.exists(out_path):
        os.makedirs(out_path)

    # load ref and test csv
    ref_utt = pd.read_csv(ref_path)['train']
    # count ngrams
    ref_count = count_ngrams(ref_utt, ngram)
    if test_set != 'gen':
        test_utt = pd.read_csv(ref_path)['train']
        test_count = count_ngrams(test_utt, ngram)
        merged_count = match_ngrams(ref_count, test_count)
        merged_count.to_csv(out_path + test_set + '.csv')

    # merge the word list
    elif test_set == 'gen':
        # go over the train and gen freq df
        temp_lst = ['0.3','0.6', '1.0', '1.5']
        gen_freq = pd.read_csv(test_path)
        for temp in temp_lst:
            test_utt = gen_freq['unprompted_' + temp]
            test_count = count_ngrams(test_utt, ngram)
            merged_count = match_ngrams(ref_count, test_count)
            merged_count.to_csv(out_path + 'gen_' + temp + '.csv')


if __name__ == "__main__":
    args = sys.argv[1:]
    main(args)



